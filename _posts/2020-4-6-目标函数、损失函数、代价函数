---
layout:     post
title:      目标函数、损失函数、代价函数.md
subtitle:   
date:       2020-4-6
author:     y00
header-img: img/asuna.jpg
catalog: true
tags:
    - 机器学习
---

损失函数loss function是描述单例训练的代价。

这里的可以是一张被放进CNN的图片，也可以是被放进线性回归模型中的一组的结构化数据。等等。

loss function这个概念是cost function从统计迁移到machine learning中形成的概念，表示机器在单张样本对于其下属特征的代价计算方法（sample=loss func(a_1*x_1+a2_x2+...）)

以神经网络举例，以一张图片作为单个样本，其中数据映射在输出层，那么就可以定义输出层上每个神经元的预测值和应该具有的真实值之间的误差作为损失函数，来描述神经元输出结果和应该具有的正确结果之间的差异度，比如为了识别手写数字，第n个神经元应该输出1来表示第n个区域应该是被激活（点亮），但实际上只有0.75的预测概率，优化这个误差就相当于让神经网络对该处的拟合性更好。

如果使用均方根误差损失函数mean_squared_error(y_true, y_pred)，true表示真实值（在二分类问题中往往是0或者1），pred表示预测值（预测某处的像素被点亮的几率是多少），将所有输出层上的误差按照均方根误差公式求和，就得出了单张样本的代价。通常在n次迭代之后，将历史迭代数据（model.history）中损失函数loss的值描绘成曲线，曲线对应的拐点（肘方法）可以认为是损失函数的值和损失函数的变化率同时达到最小的点位，取该处的损失函数对应的参数作为系统最终优化后的结果，不易陷入过拟合。

代价函数是相对于系统全局提出的概念，例如可以建立系统效用之于漏诊率与误报率（受试结果的fpr和fnr）的代价函数来描述系统整体的风险性，或者也可以说最小二乘法中的残差平方和是一种代价函数。等等。所以对于上例来说，通过训练将损失函数优化到最小之后，相当于降低了系统的经验风险（这里可以理解为对于历史的经验数据，即训练集来说，系统风险更小了）。

但是我们对系统的预期不会局限于系统能满足过去的数据，而是预期系统对将可能输入的未知数据也进行正确的预测或者分类，因此有了期望风险的概念。但实际上我们并不知道训练好的网络将会在实际使用中被读入什么样子的图片，因此期望风险是难以进行直接优化的。所以这时候可以引入结构化风险来折中经验与预期。

可以用loss+sigma来表示一个结构化风险，例如，我们可以在神经网络训练中在引入正则化惩罚项（L1或者L2）作为sigma加入在原本的loss的后面，相当于加入对权重符合一个先验分布的预期（可优化的预期），和原来的损失函数共同构成一组新的结构化代价函数。

例如对于得到相同loss值的两组权重，w1[1,0,0,0]和w2[0.25,0.25,0.25,0.25]，显然我们不是山顶洞人，我们更认同w2较w1更合理，w1对参数w1[0]过拟合，所以为了让模型更具有一般性，假设引入L2惩罚项（相当于让w（权重向量）更接近于高斯分布，和高斯分布的预期相差越大，则L2值越大，loss的值也较不加入惩罚项更高，对于上文w1和w2来说，w1更容易导致L2更大），避免模型最后优化出了导致过拟合的参数。不管使用什么方法引入结构化风险的描述，最终我们得到的就是系统的代价函数。

机器学习是通过迭代训练优化损失函数参数的过程，所以最终也就可以说机器学习的目标就是通过多次训练，来让模型训练后在使用中能对单张样本预测的loss更小，因此在这种语义下可以将目标函数理解成goal=min（cost（loss+sigma）），达成目标函数则是优化模型的关键。

上述是狭义的解释，随着这些概念被提及的多了和框架的规模应用，似乎说哪一个也不影响模型的训练和调优。习惯于不加以区分loss和cost或者goal的时期一长，如不严格区分，自然也没有区别了
