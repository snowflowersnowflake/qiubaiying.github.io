---
layout:     post
title:      Sklearn与数据比赛标程
subtitle:   #
date:       2019-10-03
author:     y00
header-img: img/asuna.jpg
catalog: true
tags:
    - python
    - Sklearn
    - 练习题
    - 机器学习
---

<iframe
  frameborder="no"
  border="0"
  marginwidth="0"
  marginheight="0"
  width="330"
  height="86"
  src="//music.163.com/outchain/player?type=2&id=27867500&auto=0&height=66"
></iframe>

# sklearn

sklearn提供了丰富的机器学习模型，例如回归、聚类、简单神经网络模型，等等，并且封装便于使用，处理数据上十分便捷

用conda或者pip可以安装

sklearn在数据竞赛中十分常用，对于基本的结构化数据题，有时不用几行代码就可以完成dataset-model-preResult的分析过程

因此本文中，主要利用数据竞赛标程来展示sklearn这个强大的机器学习库

以下标程均不用做特征工程和模型融合，因此作为sklearn的入门教程

btw，如果需要练习的数据集，可以在sklearn.dataset中获取

[官网提供dataset与example](https://scikit-learn.org/stable/auto_examples/#examples-based-on-real-world-datasets)

# 标程（全部来源于[sofasofa.io](http://sofasofa.io/tutorials/sofa_benchmark/)的练习题）

**本文在代码注释中加上了丰富的解释**

## 共享单车被借走数量预测(回归问题)

> 本练习赛的数据取自于两个城市某街道上的几处公共自行车停车桩。我们希望根据时间、天气等信息，预测出该街区在一小时内的被借取的公共自行车的数量。 


d  |	行编号，没有实际意义
--  |   --
y	|一小时内自行车被借取的数量。在test.csv中，这是需要被预测的数值。
city	|表示该行记录所发生的城市，一共两个城市
hour	|当时的时间，精确到小时，24小时计时法
is_workday	|1表示工作日，0表示节假日或者周末
temp_1	|当时的气温，单位为摄氏度
temp_2	|当时的体感温度，单位为摄氏度
weather	|当时的天气状况，1为晴朗，2为多云、阴天，3为轻度降水天气，4为强降水天气
wind	|当时的风速，数值越大表示风速越大

> 训练集中共有10000条样本，预测集中有7000条样本。 

### 线性回归模型

如果你有 1，1    2，2     3，3    4，4      5，5 
    
这样的五个坐标，用一根线去拟合，那就会得到y=x
    
线性回归就是这么一回事，用一个线性函数拟合你的train，然后如果要预测x=k的地方对应的值，就带入这个函数。


```python

# -*- coding: utf-8 -*-

# 引入模块 LinearRegression线性回归和pandas清洗数据
from sklearn.linear_model import LinearRegression
import pandas as pd

# 读取数据 pd.read_csv可以从题目给出的.csv数据集中获取到数据 submit为提交样板
train = pd.read_csv("train.csv")
test = pd.read_csv("test.csv")
submit = pd.read_csv("sample_submit.csv")

# 删除id 去掉pd_dataframe中的id列，便于建模
train.drop('id', axis=1, inplace=True)
test.drop('id', axis=1, inplace=True)

# 取出训练集的y pop出最后一列的y标签，便于在后面拟合x
y_train = train.pop('y')

# 建立线性回归模型 reg.fit需要训练集的x以及对应的y
reg = LinearRegression()
reg.fit(train, y_train)
y_pred = reg.predict(test) #然后用训练好的reg，导入test进行predict操作

# 若预测值是负数，则取0  进行lambda匹配，消灭不合理的预测结果
y_pred = map(lambda x: x if x >= 0 else 0, y_pred)

# 输出预测结果至my_LR_prediction.csv
submit['y'] = y_pred
submit.to_csv('my_LR_prediction.csv', index=False)

```
### 决策树模型

用经典的栗子来说，决策树就是：

女生要找对象，进行决策

* 不帅->0
* 帅->程序员->0
* 帅->不是程序员->没房没车->0
* 帅->不是程序员->有房有车->1

当然在许多模型中，决策可能是连续的区间分割，分类出的标签也可能不止0和1

```python
# -*- coding: utf-8 -*-

# 引入模块 
from sklearn.tree import DecisionTreeRegressor
import pandas as pd

# 读取数据
train = pd.read_csv("train.csv")
test = pd.read_csv("test.csv")
submit = pd.read_csv("sample_submit.csv")

# 删除id
train.drop('id', axis=1, inplace=True)
test.drop('id', axis=1, inplace=True)

# 取出训练集的y
y_train = train.pop('y')

# 建立最大深度为5的决策树回归模型 可以认为是决策的次数，每次决策其数据结构上来看图（树）就多出一层
reg = DecisionTreeRegressor(max_depth=5)
reg.fit(train, y_train)
y_pred = reg.predict(test)

#决策树模型会依照数据的标签为每个条件进行决策分类

# 输出预测结果至my_DT_prediction.csv
submit['y'] = y_pred
submit.to_csv('my_DT_prediction.csv', index=False)

```

## 交通事故理赔审核 （二元分类问题）

> 在交通摩擦（事故）发生后，理赔员会前往现场勘察、采集信息，这些信息往往影响着车主是否能够得到保险公司的理赔。

> 我们需要根据Q1-Q36这36条信息预测该事故方没有被理赔的概率。

CaseId	|案例编号，没有实际意义
--|--
Q1	|赔员现场勘察采集的信息，Q1代表第一个问题的信息。信息被编码成数字，数字的大小不代表真实的关系。
Qk	|上，Qk代表第k个问题的信息。一共36个问题。
Evaluation|表示最终审核结果。0表示授予理赔，1表示未通过理赔审核。在test.csv中，这是需要被预测的标签。

### LASSO逻辑回归模型

逻辑回归就是线性回归的二元分类版本

线性回归输出一个y作为预测值，在逻辑回归中通过建立映射，输出y对应的一个几率

然后通过这个几率进行 true or false 的逻辑判断

lasso是一中逻辑回归模型的方法，具体的公式推导可以自行查阅

```python

# -*- coding: utf-8 -*-

import pandas as pd
from sklearn.linear_model import LogisticRegression

# 读取数据
train = pd.read_csv("train.csv")
test = pd.read_csv("test.csv")
submit = pd.read_csv("sample_submit.csv")

# 删除id
train.drop('CaseId', axis=1, inplace=True)
test.drop('CaseId', axis=1, inplace=True)

# 取出训练集的y
y_train = train.pop('Evaluation')

# 建立LASSO逻辑回归模型 penalty代表正则化方法
# L1规范假设的是模型的参数满足拉普拉斯分布，L2假设的模型参数满足高斯分布
# 一般来说样本数据服从x分布，那么采用的统计方法也要基于这个x分布，事实上在统计学的分析方式中相当讲究分布的原理和假设检验
# 参数c表示正则化系数，越大意味着泛化程度越好，避免过拟合，但同时也代表模型的准确率可能会下降
# random_state表示随机数种子 随机数种子可以认为是一个生成器
# 打比方，在实际试验中，如果使用同样的随机数种子进行连续两次随机，那么这两次生成的序列是“完全一样的”
clf = LogisticRegression(penalty='l1', C=1.0, random_state=0)
clf.fit(train, y_train)
y_pred = clf.predict_proba(test)[:, 1]

# 输出预测结果至my_LASSO_prediction.csv
submit['Evaluation'] = y_pred
submit.to_csv('my_LASSO_prediction.csv', index=False)

```

### 随机森林模型

其实就是衍生版本的决策树算法

随机森林会根据样本生成n个决策树，每个决策树覆盖的范围各不相同，但最终都会覆盖全部的特征。

因为有多个决策树的输出结果，因此采取诸如投票等方式决定最后的标签。

如果说是决策树为 决策-结果 的映射

那么随机森林其实就是 决策森林-多结果-最终结果 的映射

```python

# -*- coding: utf-8 -*-
import pandas as pd
from sklearn.ensemble import RandomForestClassifier

# 读取数据
train = pd.read_csv("train.csv")
test = pd.read_csv("test.csv")
submit = pd.read_csv("sample_submit.csv")

# 删除id
train.drop('CaseId', axis=1, inplace=True)
test.drop('CaseId', axis=1, inplace=True)

# 取出训练集的y
y_train = train.pop('Evaluation')

# 建立随机森林模型
clf = RandomForestClassifier(n_estimators=100, random_state=0)
clf.fit(train, y_train)
y_pred = clf.predict_proba(test)[:, 1]

# 输出预测结果至my_RF_prediction.csv
submit['Evaluation'] = y_pred
submit.to_csv('my_RF_prediction.csv', index=False)

```
