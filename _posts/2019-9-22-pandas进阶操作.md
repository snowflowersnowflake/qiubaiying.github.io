---
layout:     post
title:      pandas进阶操作
subtitle:   #
date:       2019-9-22
author:     y00
header-img: img/ayano.jpg
catalog: true
tags:
    - python
    - pandas
    - 机器学习
---



<iframe
  frameborder="no"
  border="0"
  marginwidth="0"
  marginheight="0"
  width="330"
  height="86"
  src="//music.163.com/outchain/player?type=2&id=35505031&auto=0&height=66"
></iframe>





# 引言
Pandas 是基于 NumPy 的一种数据处理工具，该工具为了解决数据分析任务而创建。

Pandas 纳入了大量库和一些标准的数据模型，提供了高效地操作大型数据集所需的函数和方法。

对于机器学习算法的练习题来说，pandas更是必不可少，往往决定正确率的是特征工程而不是使用的算法模型。

pandas常常和numpy一起使用，进行数据的采样与处理。

# Pandas 的数据结构
Pandas 主要有 Series（一维数组），DataFrame（二维数组），Panel（三维数组），Panel4D（四维数组），PanelND（更多维数组）等数据结构。

其中 Series 和 DataFrame 应用的最为广泛。

* Series 是一维带标签的数组，它可以包含任何数据类型。包括整数，字符串，浮点数，Python 对象等。Series 可以通过标签来定位。
* DataFrame 是二维的带标签的数据结构。我们可以通过标签来定位数据。这是 NumPy 所没有的。

#导入所需要使用到的库

```python
import pandas as pd
import numpy as np
print(pd.__version__)#打印版本
```

# pandas进阶操作
基础的数据操作观看实例比照就能理解，进阶部分笔者会补充部分解释信息

# 时间序列索引

## 建立一个以 2018 年每一天为索引，值为随机数的 Series

```python
dti = pd.date_range(start='2018-01-01', end='2018-12-31', freq='D')
s = pd.Series(np.random.rand(len(dti)), index=dti)
print (s)
```

设置时间的起始和结束freq控制随机数的间隔频率，采用"D"的时候打印每天为单位的信息，然后将此作为index

np.random.rand返回【0,1】范围内的一个随机数

返回随机数的个数是len(dti)，以使每个Series中的索引都能匹配到一个随机数。

```txt
2018-01-01    0.289422
2018-01-02    0.322898
2018-01-03    0.663779
2018-01-04    0.513682
2018-01-05    0.996929
2018-01-06    0.303355
2018-01-07    0.466621
2018-01-08    0.079008
2018-01-09    0.775039
2018-01-10    0.198569
2018-01-11    0.401680
2018-01-12    0.126774
2018-01-13    0.875948
2018-01-14    0.086280
2018-01-15    0.048911
2018-01-16    0.687690
2018-01-17    0.765243
2018-01-18    0.623987
2018-01-19    0.407055
2018-01-20    0.802661
2018-01-21    0.644146
2018-01-22    0.511044
2018-01-23    0.426378
2018-01-24    0.769499
2018-01-25    0.011949
2018-01-26    0.667829
2018-01-27    0.295917
2018-01-28    0.114008
2018-01-29    0.201223
2018-01-30    0.791230
                ...   
2018-12-02    0.981167
2018-12-03    0.418215
2018-12-04    0.553704
2018-12-05    0.503421
2018-12-06    0.038832
2018-12-07    0.837607
2018-12-08    0.250743
2018-12-09    0.011625
2018-12-10    0.107244
2018-12-11    0.689305
2018-12-12    0.956466
2018-12-13    0.185858
2018-12-14    0.482651
2018-12-15    0.913743
2018-12-16    0.517277
2018-12-17    0.851381
2018-12-18    0.756169
2018-12-19    0.605364
2018-12-20    0.652177
2018-12-21    0.877070
2018-12-22    0.077671
2018-12-23    0.117162
2018-12-24    0.186197
2018-12-25    0.019362
2018-12-26    0.700295
2018-12-27    0.552401
2018-12-28    0.322484
2018-12-29    0.799141
2018-12-30    0.028285
2018-12-31    0.153351
Freq: D, Length: 365, dtype: float64
```
返回结果中会省略中间过程，展示头尾，底部length：表明Series中有365行，内容为浮点数

## 统计s中每一个周三对应值的和

```python
# 周一从 0 开始
print(s[s.index.weekday == 2].sum())
print()
```

```txt
27.832158328241547
```
用sum方法对s中索引为周三的内容求和打印即可，需要注意weekday从0计数

## 统计s中每个月值的平均值

```python
print(s.resample('M').mean())
print()
```

resample方法可以进行重采样

‘M’表示按照月份的方式进行时间重采样，那么原Series中的数据只会保留每月一行

mean方法用来求均值

```txt
2018-01-31    0.449804
2018-02-28    0.464638
2018-03-31    0.484023
2018-04-30    0.486435
2018-05-31    0.558915
2018-06-30    0.540861
2018-07-31    0.545044
2018-08-31    0.512989
2018-09-30    0.483962
2018-10-31    0.456614
2018-11-30    0.523259
2018-12-31    0.488175
Freq: M, dtype: float64
```

结果中对月末进行了重采样

也可以在对应的文档中可以找到该方法的说明，按照自定义的方式来重采样

## 时间转换 s->min

```python
s=pd.date_range('today',periods=100,freq='S')
ts=pd.Series(np.random.randint(0,500,len(s)),index=s)
print(ts)
print()
print(ts.resample('Min').sum())
print()
```

today表示从此刻电脑时间开始采样，以秒为单位，产生的序列赋值给s

然后s作为索引，randint生成随机的整数匹配每一个索引，产生Series指派给ts

然后按照Min的频率重采样，求和

```txt
2019-09-22 17:55:33.806691    434
2019-09-22 17:55:34.806691    254
2019-09-22 17:55:35.806691    105
2019-09-22 17:55:36.806691    114
2019-09-22 17:55:37.806691     39
2019-09-22 17:55:38.806691    127
2019-09-22 17:55:39.806691    342
2019-09-22 17:55:40.806691    117
2019-09-22 17:55:41.806691    120
2019-09-22 17:55:42.806691    179
2019-09-22 17:55:43.806691    488
2019-09-22 17:55:44.806691    140
2019-09-22 17:55:45.806691    375
2019-09-22 17:55:46.806691    277
2019-09-22 17:55:47.806691      7
2019-09-22 17:55:48.806691    212
2019-09-22 17:55:49.806691    433
2019-09-22 17:55:50.806691     67
2019-09-22 17:55:51.806691    392
2019-09-22 17:55:52.806691    361
2019-09-22 17:55:53.806691    302
2019-09-22 17:55:54.806691    189
2019-09-22 17:55:55.806691    301
2019-09-22 17:55:56.806691    494
2019-09-22 17:55:57.806691     35
2019-09-22 17:55:58.806691    135
2019-09-22 17:55:59.806691     69
2019-09-22 17:56:00.806691    332
2019-09-22 17:56:01.806691    111
2019-09-22 17:56:02.806691    325
                             ... 
2019-09-22 17:56:43.806691    337
2019-09-22 17:56:44.806691    438
2019-09-22 17:56:45.806691    452
2019-09-22 17:56:46.806691    289
2019-09-22 17:56:47.806691    306
2019-09-22 17:56:48.806691    187
2019-09-22 17:56:49.806691      3
2019-09-22 17:56:50.806691    156
2019-09-22 17:56:51.806691    322
2019-09-22 17:56:52.806691    210
2019-09-22 17:56:53.806691    117
2019-09-22 17:56:54.806691    247
2019-09-22 17:56:55.806691    322
2019-09-22 17:56:56.806691     89
2019-09-22 17:56:57.806691    134
2019-09-22 17:56:58.806691    116
2019-09-22 17:56:59.806691    416
2019-09-22 17:57:00.806691    347
2019-09-22 17:57:01.806691     62
2019-09-22 17:57:02.806691    375
2019-09-22 17:57:03.806691    458
2019-09-22 17:57:04.806691    460
2019-09-22 17:57:05.806691    491
2019-09-22 17:57:06.806691     62
2019-09-22 17:57:07.806691    307
2019-09-22 17:57:08.806691    313
2019-09-22 17:57:09.806691    426
2019-09-22 17:57:10.806691    403
2019-09-22 17:57:11.806691     21
2019-09-22 17:57:12.806691     15
Freq: S, Length: 100, dtype: int32

2019-09-22 17:55:00     6108
2019-09-22 17:56:00    15275
2019-09-22 17:57:00     3740
Freq: T, dtype: int32
```

## UTC 世界时间标准

UTC是协调世界时，具体内涵可以搜索了解。

这里仅仅作为一个时区示例，也可以用于本地化GET,CET等等时区


```python
s = pd.date_range('today', periods=1, freq='D')  # 获取当前时间
ts = pd.Series(np.random.randn(len(s)), s)  # 随机数值
print(ts)
ts_utc = ts.tz_localize('UTC')  # 转换为 UTC 时间
print(ts_utc)
```

获取当前的一个时间，匹配一个随机数

只需要用到ts.tz_localize时间本地化方法，可以按照指定时区进行本地化

可以注意到本地化前后时间内容是不变的，只是指派现在的时区是UTC

```txt
2019-09-22 18:57:49.747316   -0.377645
Freq: D, dtype: float64
2019-09-22 18:57:49.747316+00:00   -0.377645
Freq: D, dtype: float64
```

[这个文档](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.tz_localize.html)中包括了本地化和时区转换的使用细则

##  转换为上海所在时区

```python
ts_utc.tz_convert('Asia/Shanghai')
```

```txt
2019-09-23 02:57:49.747316+08:00   -0.377645
Freq: D, dtype: float64
```

之前我们将时区本地化到了UTC时区

利用convert就可以按照指定规则进行时区转换

通过字段可以了解到我们从UTC（假设现在本地时区是UTC）转到上海

得到转换后的时间

## 不同时间表示方式的转换

pandas的时间对象包括：
* timestamp时间点 表示一个具体的时间点，精确到秒
* period时期  表示某个时期，通常单位是某年、某月、某日、某小时
* timedetla时间段  表示一段时间间隔

关于这三种对象包含的方法和详细使用可以自行了解

三种对象之间可以相互转换

利用对象本身的方法，例如

```python
rng = pd.date_range('1/1/2018', periods=5, freq='M')
ts = pd.Series(np.random.randn(len(rng)), index=rng)
print(ts)
print()
ps = ts.to_period()
print(ps)
print()
print(ps.to_timestamp())
print()
```

示例了对象timestamp和period的转换过程，当字段不足会用默认值填充（见结果）

```txt
2018-01-31    0.259475
2018-02-28    0.128048
2018-03-31    0.553821
2018-04-30   -0.987806
2018-05-31    0.290521
Freq: M, dtype: float64

2018-01    0.259475
2018-02    0.128048
2018-03    0.553821
2018-04   -0.987806
2018-05    0.290521
Freq: M, dtype: float64

2018-01-01    0.259475
2018-02-01    0.128048
2018-03-01    0.553821
2018-04-01   -0.987806
2018-05-01    0.290521
Freq: MS, dtype: float64
```

## Series 多重索引

简而言之，如果你用一个多维数组去构建Series
Series中会自动匹配出多重索引
当然， 对输出操作上也可以切片

```python
letters = ['A', 'B', 'C']
numbers = list(range(10))
mi = pd.MultiIndex.from_product([letters, numbers])  # 设置多重索引
s = pd.Series(np.random.rand(30), index=mi)  # 随机数
print([letters, numbers])
print(s)
print()
print(s.loc[pd.IndexSlice[:'B', 5:]])
```

```
[['A', 'B', 'C'], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]
A  0    0.243756
   1    0.363313
   2    0.166970
   3    0.092553
   4    0.149003
   5    0.141381
   6    0.313245
   7    0.048826
   8    0.575368
   9    0.135024
B  0    0.687348
   1    0.853542
   2    0.396828
   3    0.084553
   4    0.656543
   5    0.291948
   6    0.310941
   7    0.779025
   8    0.644462
   9    0.764051
C  0    0.166460
   1    0.780991
   2    0.865861
   3    0.427068
   4    0.803411
   5    0.035250
   6    0.334675
   7    0.258239
   8    0.469680
   9    0.661562
dtype: float64

A  5    0.141381
   6    0.313245
   7    0.048826
   8    0.575368
   9    0.135024
B  5    0.291948
   6    0.310941
   7    0.779025
   8    0.644462
   9    0.764051
dtype: float64
```

## DataFrame 以多重索引创建

```python
frame = pd.DataFrame(np.arange(12).reshape(6, 2),
                     index=[list('AAABBB'), list('123123')],
                     columns=['hello', 'shiyanlou'])

print(frame)

```

通过np.arange(12).reshape(6, 2)创建12数字的向量修剪为6-2矩阵
指定aaabbb123123作为多重索引创建dataframe

```txt
     hello  shiyanlou
A 1      0          1
  2      2          3
  3      4          5
B 1      6          7
  2      8          9
  3     10         11
```
事实上索引也是可以指派名字的
可以通过frame.index.names = ['first', 'second']修改列名

## 分组求和，数据入栈
```python
frame = pd.DataFrame(np.arange(12).reshape(6, 2),
                     index=[list('AAABBB'), list('123123')],
                     columns=['hello', 'shiyanlou'])
frame.index.names = ['first', 'second']
print(frame)
print()
print(frame.groupby('first').sum())
print()
print(frame)
print()
print(frame.stack())
```
               
```txt
              hello  shiyanlou
first second                  
A     1           0          1
      2           2          3
      3           4          5
B     1           6          7
      2           8          9
      3          10         11

       hello  shiyanlou
first                  
A          6          9
B         24         27

              hello  shiyanlou
first second                  
A     1           0          1
      2           2          3
      3           4          5
B     1           6          7
      2           8          9
      3          10         11

first  second           
A      1       hello         0
               shiyanlou     1
       2       hello         2
               shiyanlou     3
       3       hello         4
               shiyanlou     5
B      1       hello         6
               shiyanlou     7
       2       hello         8
               shiyanlou     9
       3       hello        10
               shiyanlou    11
dtype: int32
```
在指派了索引名字后
frame.groupby('first')按照first索引分组求和
在这里就是输出结果按照AB各自区域求和
frame.stack()能够进行数据入栈，输出结果可以了解到数据被按照线性排列

## stack->unstack

所以通过出栈的方式还原也没问题

```python
frame = pd.DataFrame(np.arange(12).reshape(6, 2),
                     index=[list('AAABBB'), list('123123')],
                     columns=['hello', 'shiyanlou'])
frame.index.names = ['first', 'second']


f2=frame.stack()
print(f2)
print()
f3=f2.unstack()
print(f3)

```

```txt
first  second           
A      1       hello         0
               shiyanlou     1
       2       hello         2
               shiyanlou     3
       3       hello         4
               shiyanlou     5
B      1       hello         6
               shiyanlou     7
       2       hello         8
               shiyanlou     9
       3       hello        10
               shiyanlou    11
dtype: int32

              hello  shiyanlou
first second                  
A     1           0          1
      2           2          3
      3           4          5
B     1           6          7
      2           8          9
      3          10         11
```

## 条件查找
```python

data = {'animal': ['cat', 'cat', 'snake', 'dog', 'dog', 'cat', 'snake', 'cat', 'dog', 'dog'],
        'age': [2.5, 3, 0.5, np.nan, 5, 2, 4.5, np.nan, 7, 3],
        'visits': [1, 3, 2, 3, 2, 3, 1, 1, 2, 1],
        'priority': ['yes', 'yes', 'no', 'yes', 'no', 'no', 'no', 'yes', 'no', 'no']}

labels = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']
df = pd.DataFrame(data, index=labels)
print(df)
print()
#查找 `age` 大于 `3` 的全部信息
print(df[df['age'] > 3])
```

```txt
  animal  age  visits priority
a    cat  2.5       1      yes
b    cat  3.0       3      yes
c  snake  0.5       2       no
d    dog  NaN       3      yes
e    dog  5.0       2       no
f    cat  2.0       3       no
g  snake  4.5       1       no
h    cat  NaN       1      yes
i    dog  7.0       2       no
j    dog  3.0       1       no

  animal  age  visits priority
e    dog  5.0       2       no
g  snake  4.5       1       no
i    dog  7.0       2       no
```

### df 索引切片

和Series相比仅仅改变了方法名字
后面几个查询方法仅仅提供标准样例，不赘述

df.iloc[2:4, 1:3]

### DataFrame 按关键字查询

df3[df3['animal'].isin(['cat', 'dog'])]

###  DataFrame 按标签及列名查询。

df.loc[df2.index[[3, 4, 8]], ['animal', 'age']]

## DataFrame 多条件排序

```python
data = {'animal': ['cat', 'cat', 'snake', 'dog', 'dog', 'cat', 'snake', 'cat', 'dog', 'dog'],
        'age': [2.5, 3, 0.5, np.nan, 5, 2, 4.5, np.nan, 7, 3],
        'visits': [1, 3, 2, 3, 2, 3, 1, 1, 2, 1],
        'priority': ['yes', 'yes', 'no', 'yes', 'no', 'no', 'no', 'yes', 'no', 'no']}

labels = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']
df = pd.DataFrame(data, index=labels)
#ascending中false表示age按照降序,true表示visits按照升序
print(df.sort_values(by=['age', 'visits'], ascending=[False, True]))
```

```txt
  animal  age  visits priority
i    dog  7.0       2       no
e    dog  5.0       2       no
g  snake  4.5       1       no
j    dog  3.0       1       no
b    cat  3.0       3      yes
a    cat  2.5       1      yes
f    cat  2.0       3       no
c  snake  0.5       2       no
h    cat  NaN       1      yes
d    dog  NaN       3      yes
```

## DataFrame 多值替换

map+字典可以按照字典进行替换

df['priority'].map({'yes': True, 'no': False})

## DataFrame 分组求和

.groupby().sum()方法，使用同理

## DataFrame 拼接

直接用列表组装多个df对象即可

```python
temp_df1 = pd.DataFrame(np.random.randn(5, 4))  # 生成由随机数组成的 DataFrame 1
temp_df2 = pd.DataFrame(np.random.randn(5, 4))  # 生成由随机数组成的 DataFrame 2
temp_df3 = pd.DataFrame(np.random.randn(5, 4))  # 生成由随机数组成的 DataFrame 3

print(temp_df1)
print(temp_df2)
print(temp_df3)

pieces = [temp_df1, temp_df2, temp_df3]
print(pd.concat(pieces))

```

```txt
 ====
          0         1         2         3
0 -0.264635 -0.052950  0.688170 -1.914366
1 -1.288670 -0.992253 -0.228969 -0.693502
2 -1.211159  0.021853 -1.598827  0.469818
3  0.895677  0.865189 -1.102262 -1.386708
4  0.620885  1.722960  0.215481 -0.103105
          0         1         2         3
0 -0.203192 -0.635650 -0.652312 -0.959497
1  1.345722 -1.453662  1.225791 -0.408523
2 -0.418114  0.155324  1.466646  0.020927
3 -0.485332  1.754933 -1.250501  0.147999
4 -0.909008 -0.265547 -0.280067  1.734646
          0         1         2         3
0  1.140604 -1.128826 -0.601169 -0.962397
1 -0.941003 -0.324124  2.310820 -0.072020
2 -1.296052  1.425566  0.201062  1.306156
3  0.135159 -0.708848  0.684413  1.045724
4  2.373536  1.428124 -0.359993  1.402373
          0         1         2         3
0 -0.264635 -0.052950  0.688170 -1.914366
1 -1.288670 -0.992253 -0.228969 -0.693502
2 -1.211159  0.021853 -1.598827  0.469818
3  0.895677  0.865189 -1.102262 -1.386708
4  0.620885  1.722960  0.215481 -0.103105
0 -0.203192 -0.635650 -0.652312 -0.959497
1  1.345722 -1.453662  1.225791 -0.408523
2 -0.418114  0.155324  1.466646  0.020927
3 -0.485332  1.754933 -1.250501  0.147999
4 -0.909008 -0.265547 -0.280067  1.734646
0  1.140604 -1.128826 -0.601169 -0.962397
1 -0.941003 -0.324124  2.310820 -0.072020
2 -1.296052  1.425566  0.201062  1.306156
3  0.135159 -0.708848  0.684413  1.045724
4  2.373536  1.428124 -0.359993  1.402373


```

## 找出 DataFrame 表中和最小的列

```python 

df = pd.DataFrame(np.random.random(size=(5, 10)), columns=list('abcdefghij'))
print(df)
print()
print(df.sum().idxmin())  # idxmax(), idxmin() 为 Series 函数返回最大最小值的索引值

```

随机生成十列随机数
用idmin idmax 方法可以输出最大最小的列

```txt
          a         b         c  ...         h         i         j
0  0.965979  0.151651  0.353497  ...  0.964158  0.285298  0.079833
1  0.763793  0.362908  0.792489  ...  0.649987  0.827829  0.853108
2  0.129140  0.505827  0.491931  ...  0.742919  0.807635  0.661179
3  0.243242  0.087891  0.909605  ...  0.507234  0.745540  0.133692
4  0.383921  0.063741  0.999688  ...  0.430012  0.763586  0.968491

[5 rows x 10 columns]

b
```

##  每个元素减去每一行的平均值

统计常用

```python
df = pd.DataFrame(np.random.random(size=(5, 3)))
print(df)
print(df.sub(df.mean(axis=1), axis=0))
```

```txt
          0         1         2
0  0.896731  0.822522  0.576800
1  0.796234  0.147140  0.445422
2  0.748368  0.394187  0.321203
3  0.349887  0.023185  0.080568
4  0.188878  0.215437  0.980657
          0         1         2
0  0.131380  0.057171 -0.188551
1  0.333302 -0.315792 -0.017510
2  0.260448 -0.093733 -0.166716
3  0.198674 -0.128028 -0.070645
4 -0.272779 -0.246220  0.518999
```

## 透视表pivot_table

当分析庞大的数据时，为了更好的发掘数据特征之间的关系，且不破坏原数据，就可以利用透视表 `pivot_table` 进行操作。



```python
df = pd.DataFrame({'A': ['one', 'one', 'two', 'three'] * 3,
                   'B': ['A', 'B', 'C'] * 4,
                   'C': ['foo', 'foo', 'foo', 'bar', 'bar', 'bar'] * 2,
                   'D': np.random.randn(12),
                   'E': np.random.randn(12)})

print(df)
#AB作为索引进行聚合
print(pd.pivot_table(df, index=['A', 'B']))
```

实际上很好理解，就是在普通表的基础上按照某些规则进行透视，类似数据库中的table 和 view 的区别

```txt
        A  B    C         D         E
0     one  A  foo  0.228258 -0.516026
1     one  B  foo -0.856476 -1.479398
2     two  C  foo  1.509264  2.666746
3   three  A  bar  0.103100 -2.097659
4     one  B  bar  0.883371  0.430193
5     one  C  bar  0.301807 -0.686110
6     two  A  foo -1.031254  0.605358
7   three  B  foo  0.794412  0.231234
8     one  C  foo  0.579062  0.835692
9     one  A  bar -0.355812  2.394057
10    two  B  bar -1.436048  1.705509
11  three  C  bar  0.495632 -1.070289
                D         E
A     B                    
one   A -0.063777  0.939016
      B  0.013448 -0.524602
      C  0.440435  0.074791
three A  0.103100 -2.097659
      B  0.794412  0.231234
      C  0.495632 -1.070289
two   A -1.031254  0.605358
      B -1.436048  1.705509
      C  1.509264  2.666746
```

```

## 定义绝对类型
